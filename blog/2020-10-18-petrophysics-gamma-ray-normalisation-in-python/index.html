<!doctype html><html lang=en-uk><head><link href=https://gmpg.org/xfn/11 rel=profile><link rel=canonical href=https://andymcdgeo.github.io/blog/2020-10-18-petrophysics-gamma-ray-normalisation-in-python/><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta name=generator content="Hugo 0.83.1"><title>Petrophysics: Gamma Ray Normalization in Python • Andy McDonald</title><meta name=twitter:card content="summary"><meta name=twitter:title content="Petrophysics: Gamma Ray Normalization in Python"><meta name=twitter:description content="Normalization of well log data is a common and routine process within a petrophysical workflow and is used to correct for variations in logging curves between wells. These variations can arise due a number of different reasons such as incorrect tool calibrations, varying tool vintage and changes in borehole environmental conditions between the wells.
In this article we will go over:
  What normalization is
  Why we want to normalize well log data"><meta property="og:title" content="Petrophysics: Gamma Ray Normalization in Python"><meta property="og:description" content="Normalization of well log data is a common and routine process within a petrophysical workflow and is used to correct for variations in logging curves between wells. These variations can arise due a number of different reasons such as incorrect tool calibrations, varying tool vintage and changes in borehole environmental conditions between the wells.
In this article we will go over:
  What normalization is
  Why we want to normalize well log data"><meta property="og:type" content="article"><meta property="og:url" content="https://andymcdgeo.github.io/blog/2020-10-18-petrophysics-gamma-ray-normalisation-in-python/"><meta property="article:section" content="blog"><meta property="article:published_time" content="2020-10-18T00:00:00+00:00"><meta property="article:modified_time" content="2020-10-18T00:00:00+00:00"><meta property="og:site_name" content="Andy McDonald"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css><link rel=stylesheet href=/scss/hyde-hyde.a1b0c9bce32a9d5a987631e695bbe6fea465a012ae0e1d72012d3c44d516dd77.css integrity="sha256-obDJvOMqnVqYdjHmlbvm/qRloBKuDh1yAS08RNUW3Xc="><link rel=stylesheet href=/scss/print.2744dcbf8a0b2e74f8a50e4b34e5f441be7cf93cc7de27029121c6a09f9e77bc.css integrity="sha256-J0Tcv4oLLnT4pQ5LNOX0Qb58+TzH3icCkSHGoJ+ed7w=" media=print><link rel=stylesheet href=/scss/tocbot.5ef07cebc3c477b54270456f149ee02922479bb7555fd344b2c69f953b0e7e5e.css integrity="sha256-XvB868PEd7VCcEVvFJ7gKSJHm7dVX9NEssaflTsOfl4="><!--[if lt IE 9]><script src=https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js></script><script src=https://oss.maxcdn.com/respond/1.4.2/respond.min.js></script><![endif]--><link rel=apple-touch-icon-precomposed sizes=144x144 href=/apple-touch-icon-144-precomposed.png><link rel="shortcut icon" href=/favicon.png></head><body><div class=sidebar><div class=container><div class=sidebar-about><span class=site__title><a href=https://andymcdgeo.github.io/>Andy McDonald</a></span><div class=author-image><img src=https://andymcdgeo.github.io/img/andy.png alt="Author Image" class="img--circle img--headshot element--center"></div><p class=site__description>Petrophysicist | Data Scientist</p></div><div class=collapsible-menu><input type=checkbox id=menuToggle>
<label for=menuToggle>Andy McDonald</label><div class=menu-content><div><ul class=sidebar-nav><li><a href=/about/><span>About</span></a></li><li><a href=/blog/><span>Blog</span></a></li><li><a href=/projects/><span>Projects</span></a></li></ul></div><section class=social><a href=https://twitter.com/%3cusername%3e rel=me><i class="fab fa-twitter fa-lg" aria-hidden=true></i></a>
<a href=https://github.com/%3cusername%3e rel=me><i class="fab fa-github fa-lg" aria-hidden=true></i></a>
<a href=https://linkedin.com/in/%3cusername%3e rel=me><i class="fab fa-linkedin fa-lg" aria-hidden=true></i></a>
<a href=mailto:your-email@example.com rel=me><i class="fas fa-at fa-lg" aria-hidden=true></i></a></section></div></div><div class=copyright>&copy; 2021 Andy McDonald</div></div></div><div class="content container"><article><header><h1>Petrophysics: Gamma Ray Normalization in Python</h1><figure><img src=/images/featured/2020-10-18-GammaRayNormalisation.jpg alt="Petrophysics: Gamma Ray Normalization in Python" class=img-fluid></figure><div class=post__meta><i class="fas fa-calendar-alt"></i> Oct 18, 2020
in
<a class="badge badge-category" href=/categories/data-quality>DATA QUALITY</a>
•
<a class="badge badge-category" href=/categories/petrophysics>PETROPHYSICS</a>
•
<a class="badge badge-category" href=/categories/python>PYTHON</a><br><i class="fas fa-tags"></i>
<a class="badge badge-tag" href=/tags/petrophysics>petrophysics</a>
<a class="badge badge-tag" href=/tags/python>python</a>
<a class="badge badge-tag" href=/tags/normalisation>normalisation</a><br><i class="fas fa-clock"></i> 8 min read</div></header><div class=toc-wrapper><input type=checkbox id=tocToggle>
<label for=tocToggle>Table of Content</label><div class=toc id=TableOfContents></div></div><div class=post><p>Normalization of well log data is a common and routine process within a petrophysical workflow and is used to correct for variations in logging curves between wells. These variations can arise due a number of different reasons such as incorrect tool calibrations, varying tool vintage and changes in borehole environmental conditions between the wells.</p><p>In this article we will go over:</p><ul><li><p>What normalization is</p></li><li><p>Why we want to normalize well log data</p></li><li><p>How we carry out normalization</p></li><li><p>Example of normalization within Python</p></li></ul><h3 id=what-is-normalization>What is normalization?</h3><p>Normalization is the process of re-scaling or re-calibrating the well logs so that they are consistent with other logs in other wells within the field or region. This can be achieved by applying a single point normalization (linear shift) or a two point normalization (‘stretch and squeeze’) to the required curve.</p><p>Normalization is commonly applied to gamma ray logs, but can be applied to neutron porosity, bulk density, sonic and spontaneous potential logs as well. Resistivity logs are generally not normalized unless there is a sufficient reason to do so (Shier, 2004).</p><p>You should discuss with your stratigrapher/geologist prior to carrying out normalization and also carry out a thorough QC of your data to understand if it is necessary. <strong>Applying normalization blindly to your data can result in geological variation and features being removed from the data. Therefore, it should be considered carefully.</strong> Shier (2004) provides an excellent discussion and guidelines on how to carry out normalization on well log data and is well worth reviewing.</p><h3 id=why-do-we-want-to-normalize-our-well-log-data>Why do we want to normalize our well log data?</h3><p>Within a region, it is commonly assumed that similar geological and stratigraphical units should show similar minimum and maximum log values and also similar log responses. However, there are a multitude of reasons why the log responses may differ from the expected pattern between the logged wells. These can include:</p><ul><li><p>Differences in borehole environment such as lithological variations</p></li><li><p>Differences in wellbore shape affecting the measurements, for example an enlarged section of the borehole will have more borehole fluid in it and this can lead to an attenuation of gamma ray logs, which in turn leads to a reduction in values</p></li><li><p>Incorrectly applied tool calibrations</p></li><li><p>Variations in logging tool technology and sensors through time</p></li><li><p>Diagenetic changes to the rock</p></li><li><p>Drift in the tool responses</p></li><li><p>Different tools from multiple service companies</p></li></ul><p>Carrying out normalization allows us to make useful comparisons between multiple wells. It also makes batch processing more efficient, especially when selecting key interpretation parameters.</p><p>Additionally, normalization can be applied to data even if that data has been previously borehole corrected (Shier, 2004). This is useful when working with datasets where there is no knowledge of what corrections have been applied, especially in older datasets.</p><h3 id=how-do-we-normalize-well-log-data>How do we normalize well log data?</h3><p>The workflow for normalization usually involves selecting a key well within the region or field and selecting key parameters from it and re-scaling other wells to match.</p><p>Normalization can be carried out using a simple linear shift of the log data using the equation below. This is useful where we know we have a fixed shift in the data such as when neutron porosity has been recorded in different lithology units (Crain’s Petrophysics, 2020).</p><p><img src=https://cdn-images-1.medium.com/max/2000/1*1sEuscJTTBu0apWd0vyR2A.png alt></p><p>More commonly a two-point shift is applied, whereby the data is stretched and squeezed to match the reference well. This is is frequently applied to gamma ray data. This is calculated as follows:</p><p><img src=https://cdn-images-1.medium.com/max/2000/1*gfZWSfll3zSSu1TYeqKlJg.png alt></p><p>The key parameters — which are selected from the reference / key well — can be the minimum or maximum values. More commonly they are values obtained from percentiles such as the 5th and 95th percentile. If using the minimum and maximum values you need to be wary of outliers and anomalous readings. For example, if the gamma ray in the reference well read a single value of 600 API and it was used as a reference maximum value it would stretch out the other wells being normalized to this range.</p><h2 id=normalization-example-using-python>Normalization Example Using Python</h2><p>The following code walkthrough shows one way of normalizing well log data using a pandas dataframe and three wells from the Volve Dataset (Equinor, 2018).</p><p>You can find the full Jupyter Notebook for this example within **8 — Curve Normalisation.ipynb **of my Petrophysics and Python series on GitHub at the following link:
<a href=https://github.com/andymcdgeo/Petrophysics-Python-Series/><strong>andymcdgeo/Petrophysics-Python-Series</strong>
*This series of Jupyter Notebooks take you through various aspects of working with Python and Petrophysical data.*github.com</a></p><h3 id=setting-up-the-libraries-and-loading-data>Setting up The Libraries and Loading Data</h3><p>The first step is to import the required libraries that we plan to use. In this case it will be the pandas and matplotlib libraries.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    <span style=color:#f92672>import</span> pandas <span style=color:#f92672>as</span> pd
    <span style=color:#f92672>import</span> matplotlib.pyplot <span style=color:#f92672>as</span> plt
</code></pre></div><p>We can load in our data straight from CSV. In this example I am using a subset of 3 wells from the Volve dataset.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    data <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>read_csv(<span style=color:#e6db74>&#39;Data/VolveWells.csv&#39;</span>)
</code></pre></div><p>We can then obtain details about the data with a few simple commands:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    data<span style=color:#f92672>.</span>head()
</code></pre></div><p>This returns the column headers and the first 5 rows of the data:</p><p><img src=https://cdn-images-1.medium.com/max/2000/1*F7dWp9_VioPqutc9hNONuw.png alt></p><p>We can see right away what curves we have in this dataset and that the nulls are represented by NaN (Not a Number) values. Which is good and means we don’t need to replace values.</p><p>To check what wells we have in the data we can call upon the unique() method:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    data[<span style=color:#e6db74>&#39;WELL&#39;</span>]<span style=color:#f92672>.</span>unique()
</code></pre></div><p>This will return an array of the well names like so:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    array([<span style=color:#e6db74>&#39;15/9-F-1 C&#39;</span>, <span style=color:#e6db74>&#39;15/9-F-4&#39;</span>, <span style=color:#e6db74>&#39;15/9-F-7&#39;</span>], dtype<span style=color:#f92672>=</span>object)
</code></pre></div><p>From this initial exploration we can say that we have:</p><ul><li><p>3 wells within the dataset: 15/9-F-1 C, 15/9-F-4 and 15/9-F-7</p></li><li><p>There is no need to replace any -999 values as nulls</p></li><li><p>10 logging curves in each well</p></li></ul><h3 id=plotting-the-raw-data>Plotting the Raw Data</h3><p>Before we plot the data, the first step we need to do is group the dataframe by the WELL column. This will make it easier to plot on the histogram.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    wells <span style=color:#f92672>=</span> data<span style=color:#f92672>.</span>groupby(<span style=color:#e6db74>&#39;WELL&#39;</span>)
    wells<span style=color:#f92672>.</span>head()
</code></pre></div><p>We can see if we call upon wells.head() we get a grouped dataframe showing the first 5 rows from each well.</p><p><img src=https://cdn-images-1.medium.com/max/2000/1*hgLj2gF8U_udVQVDtis5_g.png alt></p><p>One of the easiest ways to compare the distribution and select key parameters is by using a histogram. In Python, if we want to see the distribution line rather than bars we have to call upon the Kernel Density Estimation (KDE) plot as opposed to the histogram. Using our grouped dataframe allows us to loop through each well, add the data to the plot and display the correct label in the legend:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    fig, ax <span style=color:#f92672>=</span> plt<span style=color:#f92672>.</span>subplots(figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>8</span>,<span style=color:#ae81ff>6</span>))
    <span style=color:#66d9ef>for</span> label, df <span style=color:#f92672>in</span> wells:
        df<span style=color:#f92672>.</span>GR<span style=color:#f92672>.</span>plot(kind <span style=color:#f92672>=</span><span style=color:#e6db74>&#39;kde&#39;</span>, ax<span style=color:#f92672>=</span>ax, label<span style=color:#f92672>=</span>label)
        plt<span style=color:#f92672>.</span>xlim(<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>200</span>)
    plt<span style=color:#f92672>.</span>grid(True)
    plt<span style=color:#f92672>.</span>legend()
    plt<span style=color:#f92672>.</span>show()
</code></pre></div><p><img src=https://cdn-images-1.medium.com/max/4800/1*buX1ViCXtJMF82s6KTzKIw.png alt></p><p>From the plot above, we will assume that the key well is 15/9-F-7 and we will normalize the other two wells to this one.</p><p>Note that it does appear that the distributions run off the left hand side of the plot, but it can be confirmed using the min() method no values exist below 0 for the gamma ray curve:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    wells<span style=color:#f92672>.</span>min()
</code></pre></div><p><img src=https://cdn-images-1.medium.com/max/2000/1*ToPigwdv_dLihjIVBXvDZg.png alt></p><h3 id=calculating-the-percentiles>Calculating the Percentiles</h3><p>As mentioned above, it is possible that datasets can contain erroneous values which may affect the minimum and the maximum values within a curve. Therefore, some interpreters prefer to base their normalization parameters on percentiles. In this example, I am going to use the 5th and 95th percentiles.</p><p>The first step is to calculate the percentile (or quantile as pandas refers to it) by grouping the data by wells and then applying the .quantile() method to a specific column. In this case, GR. The quantile function takes in a decimal value, so a value of 0.05 is equivalent to the 5th percentile and 0.95 is equivalent to the 95th percentile.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    gr_percentile_05 <span style=color:#f92672>=</span> data<span style=color:#f92672>.</span>groupby(<span style=color:#e6db74>&#39;WELL&#39;</span>)[<span style=color:#e6db74>&#39;GR&#39;</span>]<span style=color:#f92672>.</span>quantile(<span style=color:#ae81ff>0.05</span>)
    <span style=color:#66d9ef>print</span>(gr_percentile_05)
</code></pre></div><p>So now we need to bring that back into our main dataframe. We can do this using the .map() method, which will combine two data series that share a common column. Once it is mapped we can call upon the .describe() method and confirm that it has been added to the dataframe.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    data[<span style=color:#e6db74>&#39;05_PERC&#39;</span>] <span style=color:#f92672>=</span> data[<span style=color:#e6db74>&#39;WELL&#39;</span>]<span style=color:#f92672>.</span>map(gr_percentile_05)
    data<span style=color:#f92672>.</span>describe()
</code></pre></div><p>We can see that the 5th percentile data we calculated above has now been added to the end of the dataframe. We can now repeat the above process for the 95th percentile:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    gr_percentile_95 <span style=color:#f92672>=</span> data<span style=color:#f92672>.</span>groupby(<span style=color:#e6db74>&#39;WELL&#39;</span>)[<span style=color:#e6db74>&#39;GR&#39;</span>]<span style=color:#f92672>.</span>quantile(<span style=color:#ae81ff>0.95</span>)
    data[<span style=color:#e6db74>&#39;95_PERC&#39;</span>] <span style=color:#f92672>=</span> data[<span style=color:#e6db74>&#39;WELL&#39;</span>]<span style=color:#f92672>.</span>map(gr_percentile_95)
    data<span style=color:#f92672>.</span>describe()
</code></pre></div><h3 id=creating-the-normalization-function>Creating the Normalization Function</h3><p>Before we normalize our data, we must first create a function that can be called upon multiple times. As a reminder, the function we are using is as follows (Shier, 2004):</p><p><img src=https://cdn-images-1.medium.com/max/2000/1*oE88y-PcZxT1Pq3zwN3png.png alt></p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>normalise</span>(curve, ref_low, ref_high, well_low, well_high):
        <span style=color:#66d9ef>return</span> ref_low <span style=color:#f92672>+</span> ((ref_high <span style=color:#f92672>-</span> ref_low) <span style=color:#f92672>*</span> ((curve <span style=color:#f92672>-</span> well_low) <span style=color:#f92672>/</span> (well_high <span style=color:#f92672>-</span> well_low)))
</code></pre></div><p>Using the percentiles calculated in the previous step, we can set our reference high and low values:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    key_well_low <span style=color:#f92672>=</span> <span style=color:#ae81ff>25.6464</span>
    key_well_high <span style=color:#f92672>=</span> <span style=color:#ae81ff>110.5413</span>
</code></pre></div><p>To apply the function to each value and use the correct percentiles for each well we can use the .apply() method to the pandas dataframe and then a lamda function for our custom function.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    data[<span style=color:#e6db74>&#39;GR_NORM&#39;</span>] <span style=color:#f92672>=</span> data<span style=color:#f92672>.</span>apply(<span style=color:#66d9ef>lambda</span> x: normalise(x[<span style=color:#e6db74>&#39;GR&#39;</span>], key_well_low, key_well_high, x[<span style=color:#e6db74>&#39;05_PERC&#39;</span>], x[<span style=color:#e6db74>&#39;95_PERC&#39;</span>]), axis<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)
</code></pre></div><h3 id=plotting-the-normalized-data>Plotting the Normalized Data</h3><p>To view our final normalized data, we can re-use the code from above to generate the histogram. When we do, we can see that all curves have been normalized to our reference well.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>    fig, ax <span style=color:#f92672>=</span> plt<span style=color:#f92672>.</span>subplots(figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>8</span>,<span style=color:#ae81ff>6</span>))
    <span style=color:#66d9ef>for</span> label, df <span style=color:#f92672>in</span> wells:
        df<span style=color:#f92672>.</span>GR_NORM<span style=color:#f92672>.</span>plot(kind <span style=color:#f92672>=</span><span style=color:#e6db74>&#39;kde&#39;</span>, ax<span style=color:#f92672>=</span>ax, label<span style=color:#f92672>=</span>label)
        plt<span style=color:#f92672>.</span>xlim(<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>200</span>)
    plt<span style=color:#f92672>.</span>grid(True)
    plt<span style=color:#f92672>.</span>legend()
    plt<span style=color:#f92672>.</span>show()
</code></pre></div><p>We now have our normalized gamma ray data. When compared side by side we can see the difference the normalization has made to the data.</p><p><img src=https://cdn-images-1.medium.com/max/10102/1*gcbb6EF_p0wOyPKimpDDDg.png alt></p><h2 id=conclusion>Conclusion</h2><p>Normalization of well log curves is an important step within the petrophysical workflow and can be required for a variety of reasons including: poor tool calibrations, varying tool vintages, lithological differences, and borehole environmental conditions.</p><p>Carrying out normalization allows easier comparison between multiple wells and easier selection of key interpretation parameters when carrying out batch processing.</p><p>In this article we have covered how to carry out a simple normalization of a gamma ray log using Python. But the method can equally be applied to other well logs with the usual caveats that the data would need to be sense checked afterwards.</p><h2 id=references>References</h2><p>Crains Petrophysical Handbook (2020). Available at: <a href=https://www.spec2000.net/08-normalization.htm>https://www.spec2000.net/08-normalization.htm</a></p><p>Equinor. (2018). Disclosing all Volve data. Available at: <a href=https://www.equinor.com/en/news/14jun2018-disclosing-volve-data.html>https://www.equinor.com/en/news/14jun2018-disclosing-volve-data.html</a></p><p>Shier, D. E. (2004). Well log normalization: Methods and guidelines. Petrophysics, 45(3), 268–280.</p></div><div class="navigation navigation-single"><a href=/blog/2020-08-30-loading-and-displaying-well-log-data-from-las-files-with-python/ class=navigation-prev><i aria-hidden=true class="fa fa-chevron-left"></i>
<span class=navigation-tittle>Loading and Displaying Well Log Data from LAS Files with Python</span></a>
<a href=/blog/2020-10-26-visualising-well-data-coverage-using-matplotlib/ class=navigation-next><span class=navigation-tittle>Visualising Well Data Coverage Using matplotlib</span>
<i aria-hidden=true class="fa fa-chevron-right"></i></a></div><div id=disqus_thread></div><script type=text/javascript>(function(){var a,b;if(location.hostname==="localhost"||location.hostname==="127.0.0.1"||location.hostname==="")return;a=document.createElement('script'),a.type='text/javascript',a.async=!0,b='andymcdonald-scot.disqus.com',a.src='//'+b+'.disqus.com/embed.js',(document.getElementsByTagName('head')[0]||document.getElementsByTagName('body')[0]).appendChild(a)})()</script><noscript>Please enable JavaScript to view the
<a href=http://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=http://disqus.com/ class=dsq-brlink>comments powered by
<span class=logo-disqus>Disqus</span></a></article></div><script defer src=https://use.fontawesome.com/releases/v5.12.1/js/all.js integrity=sha384-ZbbbT1gw3joYkKRqh0kWyRp32UAvdqkpbLedQJSlnI8iLQcFVxaGyrOgOJiDQTTR crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/highlight.min.js></script><script type=text/javascript>hljs.initHighlightingOnLoad()</script><script src=https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.4.2/tocbot.js></script><script type=text/javascript>tocbot&&tocbot.init({tocSelector:'.toc',contentSelector:'.post',headingSelector:'h2, h3, h4',collapseDepth:4})</script></body></html>